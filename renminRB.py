#抓取人民日报import requestsimport bs4import osimport datetimeimport timedef fetchUrl(url):	headers = {		'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',		'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',	}	r=requests.get(url,headers)	r.raise_for_status()	r.encoding=r.apparent_encoding	return r.textdef getPageList(year, month, day):	'''	功能：获取当天报纸的各版面的链接列表	参数：年，月，日	'''	url = 'http://paper.people.com.cn/rmrb/html/' + year + '-' + month + '/' + day + '/nbs.D110000renmrb_01.htm'	print (url)	html = fetchUrl(url)	bsobj = bs4.BeautifulSoup(html, 'html.parser')	test1=bsobj.find_all('div', attrs={'class': 'swiper-slide'})	#pageList = bsobj.find('div', attrs={'id': 'pageList'}).ul.find_all('div', attrs={'class': 'right_title-name'})	pageList = bsobj.find('div', attrs={'class': 'swiper-container'}).find_all('div', attrs={'class': 'swiper-slide'})	linkList = []	for page in pageList:		link = page.a["href"]		url = 'http://paper.people.com.cn/rmrb/html/' + year + '-' + month + '/' + day + '/' + link		linkList.append(url)	return linkListdef getTitleList(year, month, day, pageUrl):	'''	功能：获取报纸某一版面的文章链接列表	参数：年，月，日，该版面的链接	'''	html = fetchUrl(pageUrl)	bsobj = bs4.BeautifulSoup(html, 'html.parser')	#titleList = bsobj.find('div', attrs={'id': 'titleList'}).ul.find_all('li')	titleList = bsobj.find('div', attrs={'class': 'news'}).ul.find_all('li')	linkList = []	for title in titleList:		tempList = title.find_all('a')		for temp in tempList:			link = temp["href"]			if 'nw.D110000renmrb' in link:				url = 'http://paper.people.com.cn/rmrb/html/' + year + '-' + month + '/' + day + '/' + link				linkList.append(url)	return linkListdef getContent(html):	'''	功能：解析 HTML 网页，获取新闻的文章内容	参数：html 网页内容	'''	bsobj = bs4.BeautifulSoup(html, 'html.parser')	# 获取文章 标题	# print("h3=", bsobj.h3.text)	# print("h1=", bsobj.h1.text)	# print("h2=", bsobj.h2.text)	title = bsobj.h3.text + bsobj.h1.text + bsobj.h2.text	# print(title)	# 获取文章 内容	pList = bsobj.find('div', attrs={'id': 'ozoom'}).find_all('p')	content = ''	for p in pList:		content += p.text + '\n'		# print(content)	# 返回结果 标题+内容	#resp = title + content   # return resp	return titleif __name__ == '__main__':	'''	主函数：程序入口	'''	t=datetime.date.today()	year=str(t.year)	month=str(t.month)	if t.month < 10:		month='0'+month	day=str(t.day)	if t.day <10:		day = '0'+day	pageList = getPageList(year, month, day)	for page in pageList:		titleList = getTitleList(year, month, day, page)		for url in titleList:			# 获取新闻文章内容			html = fetchUrl(url)			content = getContent(html)			print (content)